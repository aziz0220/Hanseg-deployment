{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Running on Slicer 5.6 Jupiter extension"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "351032954d84399d"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-24T21:38:11.621232Z",
     "start_time": "2024-03-24T21:38:09.179755Z"
    }
   },
   "outputs": [],
   "source": [
    "import JupyterNotebooksLib as slicernb\n",
    "import slicer\n",
    "import vtk\n",
    "import base64\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def reset_scene():\n",
    "  \"\"\"\n",
    "  Resets the Slicer scene by deleting all nodes and sets default view settings.\n",
    "  \"\"\"\n",
    "  \n",
    "      # Set viewer size to 50% of screen size\n",
    "  slicernb.AppWindow.setWindowSize(scale=1)\n",
    "    # Hide patient information from slice view\n",
    "  slicernb.showSliceViewAnnotations(True)\n",
    "    # Hide slice view controllers\n",
    "  slicer.mrmlScene.Clear(False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T21:38:11.622328Z",
     "start_time": "2024-03-24T21:38:11.621545Z"
    }
   },
   "id": "8879dc616a5aad59",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_data(case_number, dataset_path, case_names):\n",
    "  \"\"\"\n",
    "  Loads CT and MR volumes from a specific case\n",
    "\n",
    "  Args:\n",
    "      case_number: Integer representing the case number (1-42)\n",
    "      dataset_path: String containing the path to the dataset directory\n",
    "      case_names: List of strings containing case names\n",
    "\n",
    "  Returns:\n",
    "      A tuple containing the loaded CT and MR volumes as slicer nodes\n",
    "  \"\"\"\n",
    "  CT_volume = slicer.util.loadVolume(dataset_path + f\"\\\\{case_names[case_number]}\\\\{case_names[case_number]}_IMG_CT.nrrd\")\n",
    "  MR_volume = slicer.util.loadVolume(dataset_path + f\"\\\\{case_names[case_number]}\\\\{case_names[case_number]}_IMG_MR_T1.nrrd\")\n",
    "  CT_volume.AddCenteringTransform()\n",
    "  MR_volume.AddCenteringTransform()\n",
    "  slicer.vtkSlicerTransformLogic().hardenTransform(CT_volume)\n",
    "  slicer.vtkSlicerTransformLogic().hardenTransform(MR_volume)\n",
    "  \n",
    "  return CT_volume, MR_volume"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T21:38:11.630555Z",
     "start_time": "2024-03-24T21:38:11.627597Z"
    }
   },
   "id": "c50b17f101508b43",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_color_table(colorTableNode, COLOR_dict):\n",
    "  \"\"\"\n",
    "  Sets colors in a color table node based on the provided color dictionary\n",
    "\n",
    "  Args:\n",
    "      color_table_node: slicer mrml color table node\n",
    "      COLOR_dict: Dictionary mapping segment names to RGB color tuples\n",
    "  \"\"\"\n",
    "  colorTableNode.SetTypeToUser()\n",
    "  colorTableNode.SetName(\"HaN-Seg\")\n",
    "  colorTableNode.SetNumberOfColors(len(COLOR_dict))\n",
    "  colorTableNode.HideFromEditorsOff()\n",
    "  slicer.mrmlScene.AddNode(colorTableNode); colorTableNode.UnRegister(None)\n",
    "  colorTableNode.SetNamesInitialised(True)\n",
    "  for segment_name, color in COLOR_dict.items():\n",
    "      colorTableNode.AddColor(segment_name, color[0]/255, color[1]/255, color[2]/255, 1.0)         \n",
    "          "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T21:38:11.643298Z",
     "start_time": "2024-03-24T21:38:11.637696Z"
    }
   },
   "id": "26ea7963294e538c",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_and_color_segmentation(case_number, dataset_path, case_names, LABEL_dict, color_table_node, COLOR_dict):\n",
    "  \"\"\"\n",
    "  Loads segmentations for all segments except background, assigns colors,\n",
    "  and adds them to the stacked segments node\n",
    "\n",
    "  Args:\n",
    "      case_number: Integer representing the case number (1-42)\n",
    "      dataset_path: String containing the path to the dataset directory\n",
    "      case_names: List of strings containing case names\n",
    "      LABEL_dict: Dictionary mapping segment names to integer IDs\n",
    "      color_table_node: slicer mrml color table node\n",
    "  \"\"\"\n",
    "  print(f\"{case_number + 1} : Loading segmentations...\")\n",
    "  stacked_segments = slicer.mrmlScene.AddNewNodeByClass('vtkMRMLSegmentationNode', 'stacked_segments')\n",
    "  stacked_seg = stacked_segments.GetSegmentation()\n",
    "  list_of_segments = list(LABEL_dict.keys())\n",
    "  list_of_segments.remove('background')\n",
    "  \n",
    "  for seg_name in list_of_segments:\n",
    "      segmentation = slicer.util.loadSegmentation(\n",
    "          dataset_path + f\"\\\\{case_names[case_number]}\\\\{case_names[case_number]}_OAR_{seg_name}.seg.nrrd\",\n",
    "          properties={\n",
    "              'name': seg_name,\n",
    "              'colorNodeID': color_table_node.GetID()\n",
    "          },\n",
    "          returnNode=True\n",
    "      )\n",
    "      segmentationNode = slicer.util.getNode(seg_name)\n",
    "      segmentation = segmentationNode.GetSegmentation()\n",
    "  \n",
    "      # Get segment ID from LABEL_dict\n",
    "      segmentID = 'A_Carotid_L'\n",
    "  \n",
    "      # Set segment name and color directly\n",
    "      segmentation.GetSegment(segmentID).SetName(seg_name)\n",
    "      segmentColor = COLOR_dict[seg_name]\n",
    "      segmentation.GetSegment(segmentID).SetColor(segmentColor[0]/255, segmentColor[1]/255, segmentColor[2]/255)\n",
    "  \n",
    "      stacked_seg.CopySegmentFromSegmentation(segmentation, segmentID)  # Copy using correct segment ID\n",
    "  return stacked_segments\n",
    "  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T21:38:11.652818Z",
     "start_time": "2024-03-24T21:38:11.648185Z"
    }
   },
   "id": "3a29ada996804364",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def center_and_transform_segmentation(stacked_segments):\n",
    "  \"\"\"\n",
    "  Calculates the center of the segmentation and applies a transform to move it there\n",
    "\n",
    "  Args:\n",
    "    stacked_segments: slicer mrml segmentation node\n",
    "  \"\"\"\n",
    "  bounds = [0]*6\n",
    "  stacked_segments.GetRASBounds(bounds)\n",
    "  center = [(bounds[1]+bounds[0])/2, (bounds[3]+bounds[2])/2, (bounds[5]+bounds[4])/2]\n",
    "\n",
    "  transformNode = slicer.vtkMRMLLinearTransformNode()\n",
    "  slicer.mrmlScene.AddNode(transformNode)\n",
    "\n",
    "  matrix = vtk.vtkMatrix4x4()\n",
    "  matrix.SetElement(0, 3, -center[0])\n",
    "  matrix.SetElement(1, 3, -center[1])\n",
    "  matrix.SetElement(2, 3, -center[2])\n",
    "  transformNode.SetMatrixTransformToParent(matrix)\n",
    "\n",
    "  stacked_segments.SetAndObserveTransformNodeID(transformNode.GetID())\n",
    "  slicer.vtkSlicerTransformLogic().hardenTransform(stacked_segments)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T22:56:34.821315Z",
     "start_time": "2024-03-24T22:56:34.818238Z"
    }
   },
   "id": "1df003e8a757b6b8",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def visualize_and_save_data(case_number, dataset_path, case_names, output_dir, CT_volume, MR_volume, stacked_segments):\n",
    "  \"\"\"\n",
    "  Visualizes data in slice views and saves volumes and segmentation\n",
    "\n",
    "  Args:\n",
    "      case_number: Integer representing the case number (1-42)\n",
    "      dataset_path: String containing the path to the dataset directory\n",
    "      case_names: List of strings containing case names\n",
    "      output_dir: String containing the path to the output directory\n",
    "      CT_volume: slicer mrml volume node for CT data\n",
    "      MR_volume: slicer mrml volume node for MR data\n",
    "      stacked_segments: slicer mrml segmentation node for combined segments\n",
    "  \"\"\"\n",
    "  slicernb.showVolumeRendering(CT_volume, False, presetName=None)\n",
    "  slicernb.showVolumeRendering(MR_volume, False, presetName=None)\n",
    "  stacked_segments.CreateClosedSurfaceRepresentation()\n",
    "\n",
    "  slicer.util.setSliceViewerLayers(background=CT_volume)\n",
    "  slicer.util.setSliceViewerLayers(foreground=MR_volume)\n",
    "  slicer.util.setSliceViewerLayers(foregroundOpacity=0.7)\n",
    "  slicer.util.setSliceViewerLayers(label=stacked_segments)\n",
    "\n",
    "  displayNode = stacked_segments.GetDisplayNode()\n",
    "  if displayNode is not None:\n",
    "      displayNode.SetVisibility(1)\n",
    "      displayNode.SetOpacity(1.0)\n",
    "\n",
    "  result = slicernb.ViewDisplay('FourUp', center=True)\n",
    "  print(result)\n",
    "  print(f\"{case_number + 1} : Saving data...\")\n",
    "  # Save CT, MR, and segmentation volumes\n",
    "  slicer.util.saveNode(CT_volume, output_dir + f\"\\\\{case_names[case_number]}\\\\{case_names[case_number]}_IMG_CT.nrrd\")\n",
    "  slicer.util.saveNode(MR_volume, output_dir + f\"\\\\{case_names[case_number]}\\\\{case_names[case_number]}_IMG_MR_T1.nrrd\")\n",
    "  slicer.util.saveNode(stacked_segments, output_dir + f\"\\\\{case_names[case_number]}\\\\{case_names[case_number]}_stacked_segments.seg.nrrd\")\n",
    "\n",
    "  # Save screenshot as PNG\n",
    "  image_data = base64.b64decode(result.dataValue)\n",
    "  with open(output_dir + f\"\\\\{case_names[case_number]}\\\\{case_names[case_number]}_result.png\", 'wb') as file:\n",
    "      file.write(image_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T21:38:11.672408Z",
     "start_time": "2024-03-24T21:38:11.668153Z"
    }
   },
   "id": "76fd771baf4b5de0",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f09a8935a696f2f6",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 18, the missing segments are: ['OpticChiasm']\n",
      "[(18, ['OpticChiasm'])]\n",
      "Processing case 1/42: case_01\n",
      "1 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "1 : Saving data...\n",
      "Processing case 2/42: case_02\n",
      "2 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "2 : Saving data...\n",
      "Processing case 3/42: case_03\n",
      "3 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "3 : Saving data...\n",
      "Processing case 4/42: case_04\n",
      "4 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "4 : Saving data...\n",
      "Processing case 5/42: case_05\n",
      "5 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "5 : Saving data...\n",
      "Processing case 6/42: case_06\n",
      "6 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "6 : Saving data...\n",
      "Processing case 7/42: case_07\n",
      "7 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "7 : Saving data...\n",
      "Processing case 8/42: case_08\n",
      "8 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "8 : Saving data...\n",
      "Processing case 9/42: case_09\n",
      "9 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "9 : Saving data...\n",
      "Processing case 10/42: case_10\n",
      "10 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "10 : Saving data...\n",
      "Processing case 11/42: case_11\n",
      "11 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "11 : Saving data...\n",
      "Processing case 12/42: case_12\n",
      "12 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "12 : Saving data...\n",
      "Processing case 13/42: case_13\n",
      "13 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "13 : Saving data...\n",
      "Processing case 14/42: case_14\n",
      "14 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "14 : Saving data...\n",
      "Processing case 15/42: case_15\n",
      "15 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "15 : Saving data...\n",
      "Processing case 16/42: case_16\n",
      "16 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "16 : Saving data...\n",
      "Processing case 17/42: case_17\n",
      "17 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "17 : Saving data...\n",
      "Processing case 18/42: case_18\n",
      "18 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "18 : Saving data...\n",
      "Processing case 19/42: case_19\n",
      "19 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "19 : Saving data...\n",
      "Processing case 20/42: case_20\n",
      "20 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "20 : Saving data...\n",
      "Processing case 21/42: case_21\n",
      "21 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "21 : Saving data...\n",
      "Processing case 22/42: case_22\n",
      "22 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "22 : Saving data...\n",
      "Processing case 23/42: case_23\n",
      "23 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "23 : Saving data...\n",
      "Processing case 24/42: case_24\n",
      "24 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "24 : Saving data...\n",
      "Processing case 25/42: case_25\n",
      "25 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "25 : Saving data...\n",
      "Processing case 26/42: case_26\n",
      "26 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "26 : Saving data...\n",
      "Processing case 27/42: case_27\n",
      "27 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "27 : Saving data...\n",
      "Processing case 28/42: case_28\n",
      "28 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "28 : Saving data...\n",
      "Processing case 29/42: case_29\n",
      "29 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "29 : Saving data...\n",
      "Processing case 30/42: case_30\n",
      "30 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "30 : Saving data...\n",
      "Processing case 31/42: case_31\n",
      "31 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "31 : Saving data...\n",
      "Processing case 32/42: case_32\n",
      "32 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "32 : Saving data...\n",
      "Processing case 33/42: case_33\n",
      "33 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "33 : Saving data...\n",
      "Processing case 34/42: case_34\n",
      "34 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "34 : Saving data...\n",
      "Processing case 35/42: case_35\n",
      "35 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "35 : Saving data...\n",
      "Processing case 36/42: case_36\n",
      "36 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "36 : Saving data...\n",
      "Processing case 37/42: case_37\n",
      "37 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "37 : Saving data...\n",
      "Processing case 38/42: case_38\n",
      "38 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "38 : Saving data...\n",
      "Processing case 39/42: case_39\n",
      "39 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "39 : Saving data...\n",
      "Processing case 40/42: case_40\n",
      "40 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "40 : Saving data...\n",
      "Processing case 41/42: case_41\n",
      "41 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "41 : Saving data...\n",
      "Processing case 42/42: case_42\n",
      "42 : Loading segmentations...\n",
      "<JupyterNotebooksLib.display.ViewDisplay object at 0x0000017C713C1AC0>\n",
      "42 : Saving data...\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    The main function that processes all cases\n",
    "    \"\"\"\n",
    "    dataset_path = \"C:\\\\Users\\\\benam\\Downloads\\HaN-Seg\\HaN-Seg\\set_1\"\n",
    "    case_names = [f\"case_{num:02d}\" for num in range(1, 43)]\n",
    "    output_dir = \"C:\\\\Users\\\\benam\\Downloads\\HaN-Seg\\HaN-Seg\\set_2\"\n",
    "    df = pd.read_csv(dataset_path + '\\\\OAR_data.csv', delimiter=';')\n",
    "    # Iterate over the DataFrame rows\n",
    "    missing_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        # Get the case name\n",
    "        case_name = row.name\n",
    "        # Find the segments that are missing (value is 0)\n",
    "        missing_segments = row[row == 0].index.tolist()\n",
    "        # Print the case name and the missing segments\n",
    "        if(len(missing_segments) > 0):\n",
    "            print(f\"For {case_name}, the missing segments are: {missing_segments}\")\n",
    "            missing_data.append((case_name, missing_segments))\n",
    "\n",
    "    missing_data_dict = {case_num: segments for case_num, segments in missing_data}\n",
    "\n",
    "    for case_number in range(len(case_names)):\n",
    "        LABEL_dict = {\n",
    "            \"background\": 0,\n",
    "            \"A_Carotid_L\": 1,\n",
    "            \"A_Carotid_R\": 2,\n",
    "            \"Arytenoid\": 3,\n",
    "            \"Bone_Mandible\": 4,\n",
    "            \"Brainstem\": 5,\n",
    "            \"BuccalMucosa\": 6,\n",
    "            \"Cavity_Oral\": 7,\n",
    "            \"Cochlea_L\": 8,\n",
    "            \"Cochlea_R\": 9,\n",
    "            \"Cricopharyngeus\": 10,\n",
    "            \"Esophagus_S\": 11,\n",
    "            \"Eye_AL\": 12,\n",
    "            \"Eye_AR\": 13,\n",
    "            \"Eye_PL\": 14,\n",
    "            \"Eye_PR\": 15,\n",
    "            \"Glnd_Lacrimal_L\": 16,\n",
    "            \"Glnd_Lacrimal_R\": 17,\n",
    "            \"Glnd_Submand_L\": 18,\n",
    "            \"Glnd_Submand_R\": 19,\n",
    "            \"Glnd_Thyroid\": 20,\n",
    "            \"Glottis\": 21,\n",
    "            \"Larynx_SG\": 22,\n",
    "            \"Lips\": 23,\n",
    "            \"OpticChiasm\": 24,\n",
    "            \"OpticNrv_L\": 25,\n",
    "            \"OpticNrv_R\": 26,\n",
    "            \"Parotid_L\": 27,\n",
    "            \"Parotid_R\": 28,\n",
    "            \"Pituitary\": 29,\n",
    "            \"SpinalCord\": 30,\n",
    "        }\n",
    "        colors = [\n",
    "            [244, 214, 49],    # SpinalCord\n",
    "            [216, 101, 79],    # A_Carotid_L\n",
    "            [216, 101, 79],    # A_Carotid_R\n",
    "            [183, 156, 220],   # Arytenoid\n",
    "            [222, 198, 101],   # Bone_Mandible\n",
    "            [145, 92, 109],    # Brainstem\n",
    "            [178, 69, 182],    # BuccalMucosa\n",
    "            [121, 39, 153],    # Cavity_Oral\n",
    "            [104, 181, 63],    # Cochlea_L\n",
    "            [123, 174, 91],    # Cochlea_R\n",
    "            [220, 127, 211],   # Cricopharyngeus\n",
    "            [174, 125, 64],    # Esophagus_S\n",
    "            [127, 75, 38],     # Eye_AL\n",
    "            [127, 75, 38],     # Eye_AR\n",
    "            [53, 152, 174],    # Eye_PL\n",
    "            [53, 152, 174],    # Eye_PR\n",
    "            [86, 58, 127],     # Glnd_Lacrimal_L\n",
    "            [86, 58, 127],     # Glnd_Lacrimal_R\n",
    "            [222, 198, 101],   # Glnd_Submand_L\n",
    "            [222, 198, 101],   # Glnd_Submand_R\n",
    "            [62, 162, 114],    # Glnd_Thyroid\n",
    "            [47, 210, 120],    # Glottis\n",
    "            [150, 208, 243],   # Larynx_SG\n",
    "            [188, 91, 95],     # Lips\n",
    "            [99, 106, 24],     # OpticChiasm\n",
    "            [127, 24, 70],     # OpticNrv_L\n",
    "            [127, 24, 70],     # OpticNrv_R\n",
    "            [31, 45, 172],     # Parotid_L\n",
    "            [31, 45, 172],     # Parotid_R\n",
    "            [57, 157, 110]     # Pituitary\n",
    "        ]\n",
    "        COLOR_dict = {\n",
    "            \"SpinalCord\": colors[0],  # Red\n",
    "            \"A_Carotid_L\": colors[1],  # Green\n",
    "            \"A_Carotid_R\": colors[2],  # Blue\n",
    "            \"Arytenoid\": colors[3],    # Yellow\n",
    "            \"Bone_Mandible\": colors[4], # Magenta\n",
    "            \"Brainstem\": colors[5],    # Cyan\n",
    "            \"BuccalMucosa\": colors[6],  # Maroon\n",
    "            \"Cavity_Oral\": colors[7],   # Green (Lime)\n",
    "            \"Cochlea_L\": colors[8],     # Navy\n",
    "            \"Cochlea_R\": colors[9],     # Purple\n",
    "            \"Cricopharyngeus\": colors[10], # Olive\n",
    "            \"Esophagus_S\": colors[11],   # Teal\n",
    "            \"Eye_AL\": colors[12],       # Orange\n",
    "            \"Eye_AR\": colors[13],       # Spring Green\n",
    "            \"Eye_PL\": colors[14],       # Indigo\n",
    "            \"Eye_PR\": colors[15],       # Gold\n",
    "            \"Glnd_Lacrimal_L\": colors[16], # Deep Pink\n",
    "            \"Glnd_Lacrimal_R\": colors[17], # Black\n",
    "            \"Glnd_Submand_L\": colors[18], # White\n",
    "            \"Glnd_Submand_R\": colors[19], # Gray\n",
    "            \"Glnd_Thyroid\": colors[20],  # Dark Orange\n",
    "            \"Glottis\": colors[21],      # Sky Blue\n",
    "            \"Larynx_SG\": colors[22],    # Dark Cyan\n",
    "            \"Lips\": colors[23],         # Light Pink\n",
    "            \"OpticChiasm\": colors[24],   # Dark Red\n",
    "            \"OpticNrv_L\": colors[25],    # Dark Blue\n",
    "            \"OpticNrv_R\": colors[26],    # Dark Green\n",
    "            \"Parotid_L\": colors[27],     # Dark Purple\n",
    "            \"Parotid_R\": colors[28],     # Light Gold\n",
    "            \"Pituitary\": colors[29],    # Light Sky Blue\n",
    "        }\n",
    "        try:\n",
    "            removed_colors=[]\n",
    "            if case_number in missing_data_dict:\n",
    "                removed_colors.append(case_number) \n",
    "                removed_labels = missing_data_dict[case_number]\n",
    "                for color in removed_colors:\n",
    "                    colors.remove(colors[color])\n",
    "                for color in removed_colors:\n",
    "                    COLOR_dict.pop(color, None)\n",
    "                for label in removed_labels:\n",
    "                    LABEL_dict.pop(label, None)\n",
    "\n",
    "            reset_scene()\n",
    "            print(f\"Processing case {case_number + 1}/{len(case_names)}: {case_names[case_number]}\")\n",
    "\n",
    "            # Load CT and MR volumes\n",
    "            CT_volume, MR_volume = load_data(case_number, dataset_path, case_names)\n",
    "\n",
    "            # Create color table\n",
    "            colorTableNode = slicer.mrmlScene.CreateNodeByClass(\"vtkMRMLColorTableNode\")\n",
    "            create_color_table(colorTableNode, COLOR_dict)\n",
    "\n",
    "            # Load and color segmentation\n",
    "            stacked_segments = load_and_color_segmentation(case_number, dataset_path, case_names, LABEL_dict, colorTableNode, COLOR_dict)\n",
    "\n",
    "            # Center segmentation\n",
    "            center_and_transform_segmentation(stacked_segments)\n",
    "\n",
    "            # Visualize and save data\n",
    "            visualize_and_save_data(case_number, dataset_path, case_names, output_dir, CT_volume, MR_volume, stacked_segments)\n",
    "           \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing case {case_number}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T23:32:03.752683Z",
     "start_time": "2024-03-24T23:00:34.788669Z"
    }
   },
   "id": "f948fa3e04c8bd23",
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "# In this notebook, we have demonstrated how we used 3D Slicer's Jupiter Kernel extension to automatically process our medical data and apply the necessary transforms to clean it, and finally end up with a new set saved as a new clean dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da28bda9f793b518"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "slicer-5.6",
   "language": "python",
   "display_name": "Slicer 5.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
