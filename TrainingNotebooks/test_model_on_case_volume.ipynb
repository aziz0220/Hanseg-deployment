{
 "cells": [
  {
   "cell_type": "code",
   "id": "599fef9d425c11b4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:19:36.220450Z",
     "start_time": "2024-05-03T22:19:36.217378Z"
    }
   },
   "source": [
    "import nrrd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "import SimpleITK as sitk\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "global rgb_codes\n",
    "global case_names\n",
    "\n",
    "SLICE_X = True\n",
    "SLICE_Y = False\n",
    "SLICE_Z = False\n",
    "data_dir = '/mnt/c/Users/benam/Downloads/HaN-Seg/HaN-Seg/set_4/'\n",
    "model_path = data_dir+'files_3/model_3_epoch.h5'\n",
    "input_path ='/mnt/c/Users/benam/Downloads/HaN-Seg/HaN-Seg/set_2/'\n",
    "CT_path = input_path+'case_01/case_01_IMG_CT.nrrd'\n",
    "case_names = [f\"case_{num:02d}\" for num in range(1, 43)]\n",
    "LABEL_dict = {\n",
    "    \"background\": 0,\n",
    "    \"A_Carotid_L\": 1,\n",
    "    \"A_Carotid_R\": 2,\n",
    "    \"Arytenoid\": 3,\n",
    "    \"Bone_Mandible\": 4,\n",
    "    \"Brainstem\": 5,\n",
    "    \"BuccalMucosa\": 6,\n",
    "    \"Cavity_Oral\": 7,\n",
    "    \"Cochlea_L\": 8,\n",
    "    \"Cochlea_R\": 9,\n",
    "    \"Cricopharyngeus\": 10,\n",
    "    \"Esophagus_S\": 11,\n",
    "    \"Eye_AL\": 12,\n",
    "    \"Eye_AR\": 13,\n",
    "    \"Eye_PL\": 14,\n",
    "    \"Eye_PR\": 15,\n",
    "    \"Glnd_Lacrimal_L\": 16,\n",
    "    \"Glnd_Lacrimal_R\": 17,\n",
    "    \"Glnd_Submand_L\": 18,\n",
    "    \"Glnd_Submand_R\": 19,\n",
    "    \"Glnd_Thyroid\": 20,\n",
    "    \"Glottis\": 21,\n",
    "    \"Larynx_SG\": 22,\n",
    "    \"Lips\": 23,\n",
    "    \"OpticChiasm\": 24,\n",
    "    \"OpticNrv_L\": 25,\n",
    "    \"OpticNrv_R\": 26,\n",
    "    \"Parotid_L\": 27,\n",
    "    \"Parotid_R\": 28,\n",
    "    \"Pituitary\": 29,\n",
    "    \"SpinalCord\": 30,\n",
    "}\n",
    "rgb_codes = [\n",
    "    [255, 255, 255],          # Background\n",
    "            [244, 214, 49],    # SpinalCord\n",
    "            [216, 101, 79],    # A_Carotid_L\n",
    "            [216, 101, 79],    # A_Carotid_R\n",
    "            [183, 156, 220],   # Arytenoid\n",
    "            [222, 198, 101],   # Bone_Mandible\n",
    "            [145, 92, 109],    # Brainstem\n",
    "            [178, 69, 182],    # BuccalMucosa\n",
    "            [121, 39, 153],    # Cavity_Oral\n",
    "            [104, 181, 63],    # Cochlea_L\n",
    "            [123, 174, 91],    # Cochlea_R\n",
    "            [220, 127, 211],   # Cricopharyngeus\n",
    "            [174, 125, 64],    # Esophagus_S\n",
    "            [127, 75, 38],     # Eye_AL\n",
    "            [127, 75, 38],     # Eye_AR\n",
    "            [53, 152, 174],    # Eye_PL\n",
    "            [53, 152, 174],    # Eye_PR\n",
    "            [86, 58, 127],     # Glnd_Lacrimal_L\n",
    "            [86, 58, 127],     # Glnd_Lacrimal_R\n",
    "            [222, 198, 101],   # Glnd_Submand_L\n",
    "            [222, 198, 101],   # Glnd_Submand_R\n",
    "            [62, 162, 114],    # Glnd_Thyroid\n",
    "            [47, 210, 120],    # Glottis\n",
    "            [150, 208, 243],   # Larynx_SG\n",
    "            [188, 91, 95],     # Lips\n",
    "            [99, 106, 24],     # OpticChiasm\n",
    "            [127, 24, 70],     # OpticNrv_L\n",
    "            [127, 24, 70],     # OpticNrv_R\n",
    "            [31, 45, 172],     # Parotid_L\n",
    "            [31, 45, 172],     # Parotid_R\n",
    "            [57, 157, 110]  \n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:19:36.244340Z",
     "start_time": "2024-05-03T22:19:36.238620Z"
    }
   },
   "id": "220706483eb91fb8",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "def fixSlice(slice,i):\n",
    "    pre_width, pre_height = slice.shape\n",
    "    slice = np.flipud(slice)\n",
    "    image = Image.fromarray(slice) \n",
    "    new_size = max(slice.shape[0], slice.shape[1])\n",
    "    width, height = 512, 512  # Desired crop dimensions\n",
    "    image = image.resize((new_size, new_size), Image.NEAREST)\n",
    "    left = (image.width - width) // 2\n",
    "    top = (image.height - height) // 2\n",
    "    right = left + width\n",
    "    bottom = top + height\n",
    "    image = image.crop((left, top, right, bottom))\n",
    "    slice = np.array(image)\n",
    "    fgs=Image.fromarray(slice)\n",
    "    fout = os.path.join('/mnt/c/Users/benam/Downloads/HaN-Seg/HaN-Seg/set_4/slices/', f'{i}.png')\n",
    "    plt.imsave(fout,fgs,cmap='gray' )\n",
    "    image = cv2.imread(fout, cv2.IMREAD_COLOR)\n",
    "    image = image/255.0 ## (H, W, 3)\n",
    "    #image = np.stack((image,)*3, axis=-1)\n",
    "    image = np.expand_dims(image, axis=0) ## [1, H, W, 3]\n",
    "    image = image.astype(np.float32)\n",
    "    # slice = slice/255.0\n",
    "    # slice = np.stack((slice,)*3, axis=-1)  ## (H, W, 3)\n",
    "    # slice = slice.astype(np.float32)\n",
    "    return image, pre_width, pre_height"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:19:36.250185Z",
     "start_time": "2024-05-03T22:19:36.245929Z"
    }
   },
   "id": "82260bcfcb533e66",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "def sliceVolumeImage(vol):\n",
    "    (dimx, dimy, dimz) = vol.shape\n",
    "    sliced_data = []\n",
    "    if SLICE_X:\n",
    "        for i in range(dimx):\n",
    "            img, pre_width, pre_height=fixSlice(vol[i,:,:],i)\n",
    "            sliced_data.append((img, pre_width, pre_height))\n",
    "    if SLICE_Y:\n",
    "        for i in range(dimy):\n",
    "            img, pre_width, pre_height=fixSlice(vol[:,i,:])\n",
    "            sliced_data.append((img, pre_width, pre_height))\n",
    "    if SLICE_Z:\n",
    "        for i in range(dimz):\n",
    "            img, pre_width, pre_height=fixSlice(vol[:,:,i])\n",
    "            sliced_data.append((img, pre_width, pre_height))\n",
    "    return sliced_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:19:36.292337Z",
     "start_time": "2024-05-03T22:19:36.288474Z"
    }
   },
   "id": "3c48241b1347c499",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "def restoreSlice(slice, width, height):\n",
    "    slice = np.flipud(slice)\n",
    "    resize_shape = max(width, height)\n",
    "    pad_width = ((resize_shape - slice.shape[0]) // 2, (resize_shape - slice.shape[1]) // 2)\n",
    "    slice = np.pad(slice, pad_width=pad_width, mode='constant', constant_values=0)\n",
    "    image = Image.fromarray(slice) \n",
    "    image = image.resize((width, height), Image.NEAREST)\n",
    "    image = image.rotate(90)\n",
    "    slice = np.array(image)\n",
    "    #slice = slice*255.0\n",
    "    #slice = slice.astype(np.uint8)\n",
    "    return slice"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:19:36.305996Z",
     "start_time": "2024-05-03T22:19:36.301962Z"
    }
   },
   "id": "7c72e903955a05b9",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "def restoreVolumeImage(slices, width, height, depth):\n",
    "    volume = []\n",
    "    if SLICE_X:\n",
    "        print(len(slices), \" === \", width)\n",
    "        for i in range(width):\n",
    "            slice = slices[i]\n",
    "            volume.append(slice)\n",
    "    if SLICE_Y:   \n",
    "       for i in range(height):\n",
    "           slice = slices[i+width]\n",
    "           volume.append(slice)\n",
    "    if SLICE_Z:\n",
    "        for i in range(depth):\n",
    "            slice = slices[i+width+height]\n",
    "            volume.append(slice)\n",
    "    \n",
    "    return np.stack(volume, axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:19:36.321511Z",
     "start_time": "2024-05-03T22:19:36.317774Z"
    }
   },
   "id": "d839b52012ed1f20",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T22:19:36.347984Z",
     "start_time": "2024-05-03T22:19:36.344115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def grayscale_to_rgb(mask, rgb_codes):\n",
    "    h, w = mask.shape[0], mask.shape[1]\n",
    "    mask = mask.astype(np.int32)\n",
    "    output = []\n",
    "    for i, pixel in enumerate(mask.flatten()):\n",
    "        output.append(rgb_codes[pixel])\n",
    "    output = np.reshape(output, (h, w, 3))\n",
    "    return output"
   ],
   "id": "9d56c99548ad14d6",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T22:19:36.352600Z",
     "start_time": "2024-05-03T22:19:36.349480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_results(pred, save_image_path):\n",
    "\n",
    "    pred = np.expand_dims(pred, axis=-1)\n",
    "    pred = grayscale_to_rgb(pred, rgb_codes)\n",
    "    cv2.imwrite(save_image_path, pred)"
   ],
   "id": "5ba12ad8feafd4ba",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T22:19:36.367131Z",
     "start_time": "2024-05-03T22:19:36.363524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalizeImageIntensityRange(img, clip_min=0, shiftThreshold=1):\n",
    "    minimg=min(img[img > 0].flatten())\n",
    "    #print(f\"Min value is {minimg}, Max value is {max(img.flatten())}, dtype is {img.dtype}\")\n",
    "    shifted_img = img.copy()  # Create a copy to avoid in-place modification\n",
    "    if(minimg > shiftThreshold):  \n",
    "        shifted_img = shifted_img.astype(np.int16)\n",
    "        shifted_img -= minimg\n",
    "        #print(f\"Min value is {min(shifted_img.flatten())}, Max value is {max(shifted_img.flatten())}\")\n",
    "        shifted_img = np.clip(shifted_img, clip_min, None)\n",
    "        #print(f\"Min value is {min(shifted_img.flatten())},Max value is {max(shifted_img.flatten())}, MR SHAPE : {shifted_img.shape} \")\n",
    "    return shifted_img"
   ],
   "id": "8733637c03bfcf77",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T22:19:36.372316Z",
     "start_time": "2024-05-03T22:19:36.368779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def center_crop_volumes(case_number):\n",
    "    ct_image, mri_image, mask=load_data_sitk(case_number)\n",
    "    #mask = sitk.Cast(sitk.RescaleIntensity(mask), sitk.sitkUInt8)\n",
    "    mr_resampled = sitk.Resample(mri_image, ct_image)\n",
    "    ct_array = sitk.GetArrayFromImage(ct_image)\n",
    "    mri_array = sitk.GetArrayFromImage(mr_resampled)\n",
    "    mask_array = sitk.GetArrayFromImage(mask)\n",
    "    #scaled_mask = (mask_array / 255 * 31)  # Perform scaling\n",
    "    #mask_uint8 = scaled_mask.astype(np.uint8)\n",
    "    return ct_array, mri_array, mask_array"
   ],
   "id": "e5da8adbba72942f",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T22:19:36.402859Z",
     "start_time": "2024-05-03T22:19:36.398921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data_sitk(case_number):\n",
    "    CT_volume = sitk.ReadImage(input_path + f\"/{case_names[case_number]}/{case_names[case_number]}_IMG_CT.nrrd\")\n",
    "    MR_volume = sitk.ReadImage(input_path + f\"/{case_names[case_number]}/{case_names[case_number]}_IMG_MR_T1.nrrd\")\n",
    "    mask = sitk.ReadImage(input_path + f\"/{case_names[case_number]}/{case_names[case_number]}_stacked_segments.seg.nrrd\")\n",
    "    return CT_volume, MR_volume, mask"
   ],
   "id": "32fdb480948d4690",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "def predict_case(model, nrrd_path, output_path, normalize=False, case_number=0):\n",
    "  data, header = nrrd.read(nrrd_path) \n",
    "  CT_volume, MR_volume, mask = center_crop_volumes(case_number)\n",
    "  cropped_ct_image, cropped_mr_image, cropped_mask = CT_volume, MR_volume, mask\n",
    "  if normalize:\n",
    "    cropped_mr_image=normalizeImageIntensityRange(cropped_mr_image)\n",
    "  sliced_data = sliceVolumeImage(cropped_ct_image)\n",
    "  predictions = []\n",
    "  i=0\n",
    "  # Loop through slices and predict with the model\n",
    "  start_time = time.time()\n",
    "  for image_slice in sliced_data:\n",
    "    #slice = np.expand_dims(image_slice[0], axis=0) \n",
    "    predicted_slice = model.predict(image_slice[0], verbose=0)[0]\n",
    "    #pred = model.predict(slice, verbose=0)[0]\n",
    "    # Extract the predicted class (assuming model outputs class probabilities)\n",
    "    predicted_slice = np.argmax(predicted_slice, axis=-1)\n",
    "    predicted_slice = predicted_slice.astype(np.uint8)\n",
    "    # save_image_path = '/mnt/c/Users/benam/Downloads/HaN-Seg/HaN-Seg/set_4/'+ f\"results_pred/{i}.png\"\n",
    "    # save_results(predicted_slice, save_image_path)\n",
    "    i+=1\n",
    "    #predicted_slice = np.argmax(pred, axis=-1)\n",
    "    # Overlay the prediction on the original image slice (assuming grayscale)\n",
    "    #alpha = 0.99  # Adjust alpha for transparency (0 for fully transparent, 1 for opaque)\n",
    "    #overlay = predicted_slice.astype(np.float32)  # Normalize prediction for overlay\n",
    "    #print(overlay.shape)\n",
    "    #overlay = np.expand_dims(overlay, axis=-1)  # Add channel dimension if needed\n",
    "    #combined_image = alpha * overlay + (1 - alpha) * image_slice[0]\n",
    "    #combined_image = combined_image[:, :, 0]     \n",
    "    predicted_slice = restoreSlice(predicted_slice, image_slice[1], image_slice[2])\n",
    "    predictions.append(predicted_slice)\n",
    "  elapsed_time = time.time() - start_time\n",
    "  average_slice_time = elapsed_time / len(sliced_data)\n",
    "  total_slices = data.shape[0]  # Assuming data represents the full CT volume\n",
    "  average_volume_time = average_slice_time * total_slices\n",
    "  # Combine predictions back into a single volume\n",
    "  predicted_volume = restoreVolumeImage(predictions, data.shape[2], data.shape[1], data.shape[0])\n",
    "  print(f\"Average inference time per slice: {average_slice_time:.4f} seconds\")\n",
    "  print(f\"Estimated average inference time for full volume: {average_volume_time:.4f} seconds vs {elapsed_time:.4f}\")\n",
    "  print(predicted_volume.shape)\n",
    "  #predicted_volume = np.stack(predictions, axis=0)\n",
    "  # Update header for predicted data (assuming same data type)\n",
    "  predicted_header = header.copy()\n",
    "  #predicted_header['data_file'] = None  # Avoid overwriting original data\n",
    "  #predicted_header['sizes'][0] = predicted_volume.shape[0]\n",
    "  #predicted_header['sizes'][1] = predicted_volume.shape[1]\n",
    "  #predicted_header['sizes'][2] = predicted_volume.shape[2]\n",
    "  # Save the predicted nrrd file\n",
    "  nrrd.write(output_path, predicted_volume, predicted_header)\n",
    "  print(f\"Prediction saved to: {output_path}\")\n",
    "  return predicted_volume"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:19:36.420241Z",
     "start_time": "2024-05-03T22:19:36.414878Z"
    }
   },
   "id": "initial_id",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "model=tf.keras.models.load_model(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:19:40.597399Z",
     "start_time": "2024-05-03T22:19:36.429885Z"
    }
   },
   "id": "95a10fdeac07a45f",
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": "predicted_volume = predict_case(model, CT_path, output_path= input_path+\"case_01/case_01_Prediction_CT.seg.nrrd\", normalize=False, case_number=0)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:20:25.438261Z",
     "start_time": "2024-05-03T22:19:40.599103Z"
    }
   },
   "id": "15b78216813264bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202  ===  202\n",
      "Average inference time per slice: 0.0903 seconds\n",
      "Estimated average inference time for full volume: 92.4405 seconds vs 18.2353\n",
      "(1024, 1024, 202)\n",
      "Prediction saved to: /mnt/c/Users/benam/Downloads/HaN-Seg/HaN-Seg/set_2/case_01/case_01_Prediction_CT.seg.nrrd\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": "# predicted_volume.shape",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:20:25.442054Z",
     "start_time": "2024-05-03T22:20:25.439559Z"
    }
   },
   "id": "428bf28e4f7ed78e",
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": "# from matplotlib import pyplot as plt",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:20:25.545778Z",
     "start_time": "2024-05-03T22:20:25.443909Z"
    }
   },
   "id": "afcfe7ae52dfa145",
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": "# plt.imshow(predicted_volume[:,:,100])",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:20:25.550522Z",
     "start_time": "2024-05-03T22:20:25.547141Z"
    }
   },
   "id": "5dd520b2d24b2ddf",
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": "# plt.imshow(mask[:,:,100])",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:20:25.555608Z",
     "start_time": "2024-05-03T22:20:25.552527Z"
    }
   },
   "id": "38ca7f823e73f2f2",
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": "# plt.imshow(data[:,:,100])",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:20:25.560230Z",
     "start_time": "2024-05-03T22:20:25.557254Z"
    }
   },
   "id": "788a7ab8b3dba23d",
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": "# mask_path = '/mnt/c/Users/benam/Downloads/HaN-Seg/HaN-Seg/set_2/case_02/case_02_stacked_segments.seg.nrrd'",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:20:25.565008Z",
     "start_time": "2024-05-03T22:20:25.561711Z"
    }
   },
   "id": "dcd01ed8163b3208",
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "source": "# mask, header = nrrd.read(mask_path)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:20:25.569821Z",
     "start_time": "2024-05-03T22:20:25.566964Z"
    }
   },
   "id": "57256c2a469228fe",
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "source": "# data, header = nrrd.read(CT_path)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T22:20:25.574765Z",
     "start_time": "2024-05-03T22:20:25.572106Z"
    }
   },
   "id": "6d5a6bfdf801a34d",
   "outputs": [],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
